<div align="center">
  <!-- <h1><b>  </b></h1> -->
  <!-- <h2><b>  </b></h2> -->
  <h2><b> TableTime: Reformulating Time Series Classification as Training-Free Table Understanding with Large Language Models (CIKM'2025)</b></h2>
</div>

<div align="center">

![](https://img.shields.io/github/last-commit/realwangjiahao/TableTime?color=green)
![](https://img.shields.io/github/stars/realwangjiahao/TableTime?color=yellow)
![](https://img.shields.io/github/forks/realwangjiahao/TableTime?color=lightblue)
![](https://img.shields.io/badge/PRs-Welcome-green)

</div>

<div align="center">


**[<a href="https://arxiv.org/abs/2411.15737">Paper Page</a>]**
**[<a href="https://www.themoonlight.io/en/review/tabletime-reformulating-time-series-classification-as-training-free-table-understanding-with-large-language-models">MoonLight</a>]**


**[<a href="https://mp.weixin.qq.com/s/7TTO8osQED9yqQ70s9Ruxw">Êó∂Â∫è‰∫∫‰∏≠ÊñáËß£ËØª</a>]**
**[<a href="https://mp.weixin.qq.com/s/CnFpm-fuplmDEcKmC_pMGA">AIÁßëÁ†îÊäÄÊúØÊ¥æ‰∏≠ÊñáËß£ËØª</a>]**
**[<a href="https://mp.weixin.qq.com/s/QMVzBH7I3nkuT5QN4kNQ6A">Ê∂åÁé∞ËÅöÁÇπ‰∏≠ÊñáËß£ËØª</a>]**


</div>

---
> üëè The paper is accpeted by CIKM 2025!
>
> üôã Please let us know if you find out a mistake or have any suggestions!
> 
> üåü If you find this resource helpful, please consider to star this repository and cite our research:

```bibtex
@article{wang2024tabletime,
  title={Tabletime: Reformulating time series classification as zero-shot table understanding via large language models},
  author={Wang, Jiahao and Cheng, Mingyue and Mao, Qingyang and Liu, Qi and Xu, Feiyang and Li, Xin and Chen, Enhong},
  journal={arXiv e-prints},
  pages={arXiv--2411},
  year={2024}
}
```
## Motivation

In today's data-driven world, multivariate time series (MTS) are widely used in fields such as healthcare, industrial monitoring, and human behavior recognition. By recording temporal information across multiple dimensions, these data provide a rich foundation for decision support and trend analysis. However, traditional time series classification (TSC) methods have significant limitations in capturing temporal dependencies and multi-channel characteristics. While deep learning techniques have significantly improved the performance of time series classification, the high complexity and "black-box" nature of the models have limited their widespread adoption in practical applications.

In recent years, the powerful reasoning capabilities and cross-domain generalization of large language models (LLMs) have brought new possibilities to time series data analysis. However, directly applying LLMs to time series classification tasks still faces numerous challenges, such as the mismatch between time series data and the semantic space of text, high computational costs, and the inefficient use of model reasoning capabilities. To overcome these bottlenecks, we propose **TableTime**, a novel time series classification framework based on table comprehension, which aims to fully leverage the reasoning power of LLMs, redefine multivariate time series classification as a table comprehension task, and open up a new paradigm for time series data analysis.

![](pic/background.png)<center></center>

## Method

## Experimental Result

## How to run the code

## Further Reading
```bibtex
@article{wang2025can,
  title={Can slow-thinking llms reason over time? empirical studies in time series forecasting},
  author={Wang, Jiahao and Cheng, Mingyue and Liu, Qi},
  journal={arXiv preprint arXiv:2505.24511},
  year={2025}
}
```









